{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파라미터 튜닝 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = datasets.load_boston()\n",
    "x = data['data']\n",
    "y = data['target']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파라미터 튜닝의 경우 grid search를 이용하여 진행할 수 있다. grid search를 활용하는 방법은 parameter grid를 dictionary 형태로 구성하여 grid search를 진행할 수 있다.\n",
    "\n",
    "- param_grid : 파라미터 셋을 정의하고 해당 알고리즘의 파라미터 이름을 key로, search하고자는 수치의 list를 value로하는 dictionary를 만든다.\n",
    "- GridSearchCV : 모델과 앞서 정의한 param_grid를 입력하고, cross-validation(cv) 를 입력한다. 또한, 해당 모델의 평가 metric을 정의하면 해당 평가 metric기반으로 cross-validation을 통해 최적 파라미터를 찾는다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'n_estimators': [10, 20, 30, 40, 50], 'max_features': [2, 3, 4], 'bootstrap': [True, False]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators = [10,20,30,40,50]\n",
    "max_featrues = [2,3,4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "param_grid = [{'n_estimators' : n_estimators,  #이름 정확히 똑같이 써줘야한다. \n",
    "               'max_features': max_featrues,\n",
    "              'bootstrap': bootstrap}]   # 30가지 조합으로 튜닝\n",
    "\n",
    "rf = RandomForestRegressor()   #이건 pipeline을 쓰지 않기때문에 간단하게 이렇게 작성할 수 있음\n",
    "grid_search = GridSearchCV(rf, param_grid=param_grid, cv = 4, # 4 fold cross-validation\n",
    "                          scoring='neg_mean_squared_error')  #이건 -mse값이라서, 나중에 rmse를 구할때 -를 붙어야줘야함\n",
    "                                                            # 내부적으로는 최대화하려고하기때문에 negative해서 최대화해서 값을 가져오려함\n",
    "\n",
    "grid_search.fit(X_train, Y_train)  # best parameter을 찾기위함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False, 'max_features': 4, 'n_estimators': 30}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.96856902586 {'bootstrap': True, 'max_features': 2, 'n_estimators': 10}\n",
      "3.94134053129 {'bootstrap': True, 'max_features': 2, 'n_estimators': 20}\n",
      "3.6616651473 {'bootstrap': True, 'max_features': 2, 'n_estimators': 30}\n",
      "3.61098888791 {'bootstrap': True, 'max_features': 2, 'n_estimators': 40}\n",
      "3.64762180863 {'bootstrap': True, 'max_features': 2, 'n_estimators': 50}\n",
      "3.73231301634 {'bootstrap': True, 'max_features': 3, 'n_estimators': 10}\n",
      "3.34851972102 {'bootstrap': True, 'max_features': 3, 'n_estimators': 20}\n",
      "3.34663254216 {'bootstrap': True, 'max_features': 3, 'n_estimators': 30}\n",
      "3.57489622197 {'bootstrap': True, 'max_features': 3, 'n_estimators': 40}\n",
      "3.39142973867 {'bootstrap': True, 'max_features': 3, 'n_estimators': 50}\n",
      "3.64250146865 {'bootstrap': True, 'max_features': 4, 'n_estimators': 10}\n",
      "3.53349980953 {'bootstrap': True, 'max_features': 4, 'n_estimators': 20}\n",
      "3.53135281433 {'bootstrap': True, 'max_features': 4, 'n_estimators': 30}\n",
      "3.45705455052 {'bootstrap': True, 'max_features': 4, 'n_estimators': 40}\n",
      "3.21459790388 {'bootstrap': True, 'max_features': 4, 'n_estimators': 50}\n",
      "3.64442822157 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n",
      "3.53623857548 {'bootstrap': False, 'max_features': 2, 'n_estimators': 20}\n",
      "3.307625589 {'bootstrap': False, 'max_features': 2, 'n_estimators': 30}\n",
      "3.23672363518 {'bootstrap': False, 'max_features': 2, 'n_estimators': 40}\n",
      "3.31798927778 {'bootstrap': False, 'max_features': 2, 'n_estimators': 50}\n",
      "3.45932343733 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n",
      "3.38092277441 {'bootstrap': False, 'max_features': 3, 'n_estimators': 20}\n",
      "3.20711230464 {'bootstrap': False, 'max_features': 3, 'n_estimators': 30}\n",
      "3.11970013577 {'bootstrap': False, 'max_features': 3, 'n_estimators': 40}\n",
      "3.17069196675 {'bootstrap': False, 'max_features': 3, 'n_estimators': 50}\n",
      "3.73471808963 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n",
      "3.33872610733 {'bootstrap': False, 'max_features': 4, 'n_estimators': 20}\n",
      "3.11664361453 {'bootstrap': False, 'max_features': 4, 'n_estimators': 30}\n",
      "3.22561164436 {'bootstrap': False, 'max_features': 4, 'n_estimators': 40}\n",
      "3.27370923889 {'bootstrap': False, 'max_features': 4, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_   # 모든 파라미터의 결과들을 알수있음\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)   # RMSE값 mse값이 -로 구해졌으므로 -를 붙임!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 개별 실습 시간\n",
    "\n",
    "수업시간에 다룬 알고리즘 중, 하나를 선택하여 scikit-learn에서 제공하는 데이터를 활용하여 주요 파라미터를 튜닝하여 최종 모델을 하나 얻어내세요.\n",
    "수업자료를 활용하여 주요파라미터들을 grid search로 찾아내는 과정을 진행해보세요.\n",
    "기존의 random forest를 이용하실 경우엔, 좀 더 다양한 파라미터를 설정해보세요.\n",
    "\n",
    " - scikit-learn 데이터 관련 설명 : https://scikit-learn.org/stable/datasets/index.html\n",
    " - load_boston(regression용) 또는 load_iris(classification) 를  활용하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "뭘 3가지 이상잡지? 변수를? 데이터입력부터 파라미터 튜닝까지 해라! regression이나 classification\n",
    "배깅, 부팅, 랜덤포레스트, 트리 등등 골라서 모델 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data= datasets.load_iris()\n",
    "x= data['data']\n",
    "y= data['target']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'n_estimators': [10, 20, 30, 40, 50], 'learning_rate': [0.1, 0.2, 0.3], 'max_depth': [2, 3, 4]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators=[10, 20, 30, 40, 50]\n",
    "learning_rate=[0.1, 0.2, 0.3]\n",
    "max_depth= [2,3,4]\n",
    "\n",
    "param_grid= [{'n_estimators': n_estimators,\n",
    "             'learning_rate': learning_rate,\n",
    "             'max_depth': max_depth}]\n",
    "\n",
    "gbm_cl= GradientBoostingClassifier()\n",
    "grid_search = GridSearchCV(gbm_cl, param_grid = param_grid, cv=5, scoring ='accuracy')\n",
    "\n",
    "grid_search.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 10}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_   # best parameter을 구함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.942857142857 {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 10}\n",
      "0.942857142857 {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 20}\n",
      "0.942857142857 {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 30}\n",
      "0.942857142857 {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 40}\n",
      "0.942857142857 {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 50}\n",
      "0.952380952381 {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 10}\n",
      "0.942857142857 {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 20}\n",
      "0.942857142857 {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 30}\n",
      "0.942857142857 {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 40}\n",
      "0.942857142857 {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.952380952381 {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 10}\n",
      "0.952380952381 {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 20}\n",
      "0.952380952381 {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 30}\n",
      "0.952380952381 {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 40}\n",
      "0.952380952381 {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 50}\n",
      "0.942857142857 {'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 10}\n",
      "0.942857142857 {'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 20}\n",
      "0.942857142857 {'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 30}\n",
      "0.942857142857 {'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 40}\n",
      "0.942857142857 {'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 50}\n",
      "0.942857142857 {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 10}\n",
      "0.942857142857 {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 20}\n",
      "0.942857142857 {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 30}\n",
      "0.942857142857 {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 40}\n",
      "0.942857142857 {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.952380952381 {'learning_rate': 0.2, 'max_depth': 4, 'n_estimators': 10}\n",
      "0.952380952381 {'learning_rate': 0.2, 'max_depth': 4, 'n_estimators': 20}\n",
      "0.942857142857 {'learning_rate': 0.2, 'max_depth': 4, 'n_estimators': 30}\n",
      "0.952380952381 {'learning_rate': 0.2, 'max_depth': 4, 'n_estimators': 40}\n",
      "0.952380952381 {'learning_rate': 0.2, 'max_depth': 4, 'n_estimators': 50}\n",
      "0.942857142857 {'learning_rate': 0.3, 'max_depth': 2, 'n_estimators': 10}\n",
      "0.942857142857 {'learning_rate': 0.3, 'max_depth': 2, 'n_estimators': 20}\n",
      "0.952380952381 {'learning_rate': 0.3, 'max_depth': 2, 'n_estimators': 30}\n",
      "0.952380952381 {'learning_rate': 0.3, 'max_depth': 2, 'n_estimators': 40}\n",
      "0.942857142857 {'learning_rate': 0.3, 'max_depth': 2, 'n_estimators': 50}\n",
      "0.942857142857 {'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 10}\n",
      "0.942857142857 {'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 20}\n",
      "0.942857142857 {'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 30}\n",
      "0.942857142857 {'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 40}\n",
      "0.942857142857 {'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 50}\n",
      "0.952380952381 {'learning_rate': 0.3, 'max_depth': 4, 'n_estimators': 10}\n",
      "0.952380952381 {'learning_rate': 0.3, 'max_depth': 4, 'n_estimators': 20}\n",
      "0.952380952381 {'learning_rate': 0.3, 'max_depth': 4, 'n_estimators': 30}\n",
      "0.952380952381 {'learning_rate': 0.3, 'max_depth': 4, 'n_estimators': 40}\n",
      "0.952380952381 {'learning_rate': 0.3, 'max_depth': 4, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "# print(cvres)\n",
    "\n",
    "for accuracy, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(accuracy, params)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_.fit(X_train, Y_train) # 가장 좋은 성능을 가진 parameter의 모델을 가지고 fit진행\n",
    "# 이게 retrained model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34  0  0]\n",
      " [ 0 32  0]\n",
      " [ 0  0 39]]\n"
     ]
    }
   ],
   "source": [
    "cm= confusion_matrix(Y_train,best_model.predict(X_train))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "score= accuracy_score(Y_train, best_model.predict(X_train))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.977777777778\n"
     ]
    }
   ],
   "source": [
    "score= accuracy_score(Y_test, y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
