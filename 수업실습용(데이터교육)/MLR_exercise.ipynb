{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 다중 회귀 분석 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이썬에서 Multiple Linear Regression을 실행하기 위해 scikit-learn 패키지를 사용\n",
    "보통은 데이터를 외부에서 읽어들여 전처리 후 모델링을 진행하지만, 기존의 scikit-learn에 샘플데이터셋이 있으므로 이를 이용하여 실습을 진행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이썬에서 패키지를 사용하기 위해서는 'import' 함수를 사용하며,\n",
    "만약에 패키지 중 일부만을 사용하고자 할 때는 'from package import subpackage'를 진행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 패키지 import 및 데이터 load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 셋의 형태를 파악하기 위해 데이터를 출력해본다. 데이터셋의 형태는 딕셔너리 형태로, key가 data와 target으로 구분되어있다. 친절하게 scikit-learn에서는 데이터를 미리 전처리해두어서 data(X, 독립변수), target(Y, 종속변수)로 구분지어놨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
      "         0.01990842, -0.01764613],\n",
      "       [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
      "        -0.06832974, -0.09220405],\n",
      "       [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
      "         0.00286377, -0.02593034],\n",
      "       ..., \n",
      "       [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
      "        -0.04687948,  0.01549073],\n",
      "       [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
      "         0.04452837, -0.02593034],\n",
      "       [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
      "        -0.00421986,  0.00306441]]), 'target': array([ 151.,   75.,  141.,  206.,  135.,   97.,  138.,   63.,  110.,\n",
      "        310.,  101.,   69.,  179.,  185.,  118.,  171.,  166.,  144.,\n",
      "         97.,  168.,   68.,   49.,   68.,  245.,  184.,  202.,  137.,\n",
      "         85.,  131.,  283.,  129.,   59.,  341.,   87.,   65.,  102.,\n",
      "        265.,  276.,  252.,   90.,  100.,   55.,   61.,   92.,  259.,\n",
      "         53.,  190.,  142.,   75.,  142.,  155.,  225.,   59.,  104.,\n",
      "        182.,  128.,   52.,   37.,  170.,  170.,   61.,  144.,   52.,\n",
      "        128.,   71.,  163.,  150.,   97.,  160.,  178.,   48.,  270.,\n",
      "        202.,  111.,   85.,   42.,  170.,  200.,  252.,  113.,  143.,\n",
      "         51.,   52.,  210.,   65.,  141.,   55.,  134.,   42.,  111.,\n",
      "         98.,  164.,   48.,   96.,   90.,  162.,  150.,  279.,   92.,\n",
      "         83.,  128.,  102.,  302.,  198.,   95.,   53.,  134.,  144.,\n",
      "        232.,   81.,  104.,   59.,  246.,  297.,  258.,  229.,  275.,\n",
      "        281.,  179.,  200.,  200.,  173.,  180.,   84.,  121.,  161.,\n",
      "         99.,  109.,  115.,  268.,  274.,  158.,  107.,   83.,  103.,\n",
      "        272.,   85.,  280.,  336.,  281.,  118.,  317.,  235.,   60.,\n",
      "        174.,  259.,  178.,  128.,   96.,  126.,  288.,   88.,  292.,\n",
      "         71.,  197.,  186.,   25.,   84.,   96.,  195.,   53.,  217.,\n",
      "        172.,  131.,  214.,   59.,   70.,  220.,  268.,  152.,   47.,\n",
      "         74.,  295.,  101.,  151.,  127.,  237.,  225.,   81.,  151.,\n",
      "        107.,   64.,  138.,  185.,  265.,  101.,  137.,  143.,  141.,\n",
      "         79.,  292.,  178.,   91.,  116.,   86.,  122.,   72.,  129.,\n",
      "        142.,   90.,  158.,   39.,  196.,  222.,  277.,   99.,  196.,\n",
      "        202.,  155.,   77.,  191.,   70.,   73.,   49.,   65.,  263.,\n",
      "        248.,  296.,  214.,  185.,   78.,   93.,  252.,  150.,   77.,\n",
      "        208.,   77.,  108.,  160.,   53.,  220.,  154.,  259.,   90.,\n",
      "        246.,  124.,   67.,   72.,  257.,  262.,  275.,  177.,   71.,\n",
      "         47.,  187.,  125.,   78.,   51.,  258.,  215.,  303.,  243.,\n",
      "         91.,  150.,  310.,  153.,  346.,   63.,   89.,   50.,   39.,\n",
      "        103.,  308.,  116.,  145.,   74.,   45.,  115.,  264.,   87.,\n",
      "        202.,  127.,  182.,  241.,   66.,   94.,  283.,   64.,  102.,\n",
      "        200.,  265.,   94.,  230.,  181.,  156.,  233.,   60.,  219.,\n",
      "         80.,   68.,  332.,  248.,   84.,  200.,   55.,   85.,   89.,\n",
      "         31.,  129.,   83.,  275.,   65.,  198.,  236.,  253.,  124.,\n",
      "         44.,  172.,  114.,  142.,  109.,  180.,  144.,  163.,  147.,\n",
      "         97.,  220.,  190.,  109.,  191.,  122.,  230.,  242.,  248.,\n",
      "        249.,  192.,  131.,  237.,   78.,  135.,  244.,  199.,  270.,\n",
      "        164.,   72.,   96.,  306.,   91.,  214.,   95.,  216.,  263.,\n",
      "        178.,  113.,  200.,  139.,  139.,   88.,  148.,   88.,  243.,\n",
      "         71.,   77.,  109.,  272.,   60.,   54.,  221.,   90.,  311.,\n",
      "        281.,  182.,  321.,   58.,  262.,  206.,  233.,  242.,  123.,\n",
      "        167.,   63.,  197.,   71.,  168.,  140.,  217.,  121.,  235.,\n",
      "        245.,   40.,   52.,  104.,  132.,   88.,   69.,  219.,   72.,\n",
      "        201.,  110.,   51.,  277.,   63.,  118.,   69.,  273.,  258.,\n",
      "         43.,  198.,  242.,  232.,  175.,   93.,  168.,  275.,  293.,\n",
      "        281.,   72.,  140.,  189.,  181.,  209.,  136.,  261.,  113.,\n",
      "        131.,  174.,  257.,   55.,   84.,   42.,  146.,  212.,  233.,\n",
      "         91.,  111.,  152.,  120.,   67.,  310.,   94.,  183.,   66.,\n",
      "        173.,   72.,   49.,   64.,   48.,  178.,  104.,  132.,  220.,   57.]), 'DESCR': 'Diabetes dataset\\n================\\n\\nNotes\\n-----\\n\\nTen baseline variables, age, sex, body mass index, average blood\\npressure, and six blood serum measurements were obtained for each of n =\\n442 diabetes patients, as well as the response of interest, a\\nquantitative measure of disease progression one year after baseline.\\n\\nData Set Characteristics:\\n\\n  :Number of Instances: 442\\n\\n  :Number of Attributes: First 10 columns are numeric predictive values\\n\\n  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\\n\\n  :Attributes:\\n    :Age:\\n    :Sex:\\n    :Body mass index:\\n    :Average blood pressure:\\n    :S1:\\n    :S2:\\n    :S3:\\n    :S4:\\n    :S5:\\n    :S6:\\n\\nNote: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\\n\\nSource URL:\\nhttp://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\\n\\nFor more information see:\\nBradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\\n(http://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\\n', 'feature_names': ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']}\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력받은 데이터를 X,Y로 구분하여 처리한다. x 데이터의 형태를 확인하기 위해 아래와 같이 진행한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10)\n"
     ]
    }
   ],
   "source": [
    "x = data['data']\n",
    "y = data['target']   # = data.target\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 분할은 scikit-learn에서 제공하는 train_test_split을 이용하면 편리하다. 아래와 같이 split을 하게되면 하나의 데이터로 부터 특정 비율만큼을 트레이닝셋으로, 나머지를 테스트셋으로 구분하여 활용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((309, 10), (133, 10), (309,), (133,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.3, random_state=0)  # 30%가 test size\n",
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn에서의 모델 트레이닝은 매우 간단한데, 아래와 같이 특정 모델의 객체를 생성 한 후, 각 객체에 공통적으로 존재하는 fit함수를 사용하면 주어진 데이터에 대해서 학습을 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr = LinearRegression()    # 모델객체생성\n",
    "mlr.fit(X_train, Y_train)    # fit으로 학습진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLR 모델에서 추정한 회귀변수를 보고자 한다면 아래와 같이 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [ -52.46990775 -193.51064552  579.4827762   272.46404234 -504.72401371\n",
      "  241.68441866  -69.73618783   86.62018451  721.95580222   26.77887028]\n"
     ]
    }
   ],
   "source": [
    "# The coefficients\n",
    "print('Coefficients: \\n', mlr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 적합성을 확인하기 위해 수업시간에 배운 R-square를 구해보자.\n",
    "여러가지 metric은 scikit-learn에서 사용할 수 있도록 모듈로 구성되어 있으므로, 이를 import하여 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.392893984507\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "pred = mlr.predict(X_test)    # predict 다른 모델도 항상 똑같은 함수 씀\n",
    "print(r2_score(Y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추가 패키지 사용 - statsmodels 패키지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "statsmodels 패키지에서는 OLS 클래스를 이용하여 선형회귀분석을 실시한다. 아래와 같이 패키지를 입력하고, OLS 모형을 이용하여 회귀분석을 실시한다. scikit-learn과의 차이점은 아래와 같다. \n",
    "- 모델 객체 생성시 미리 데이터를 입력해줘야한다. \n",
    "- 자동으로 상수항을 만들지 않기 때문에 'add_constant'를 이용하여 상수항을 추가해줘야 한다. \n",
    "\n",
    "아래는 결과 summary를 확인하기 위해 상수항은 따로 추가하지 않고 실행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.regression.linear_model import OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.106\n",
      "Model:                            OLS   Adj. R-squared:                  0.076\n",
      "Method:                 Least Squares   F-statistic:                     3.554\n",
      "Date:                Mon, 15 Jul 2019   Prob (F-statistic):           0.000183\n",
      "Time:                        15:25:38   Log-Likelihood:                -2010.9\n",
      "No. Observations:                 309   AIC:                             4042.\n",
      "Df Residuals:                     299   BIC:                             4079.\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1           -94.5943    217.856     -0.434      0.664    -523.320     334.131\n",
      "x2          -108.8227    220.067     -0.494      0.621    -541.900     324.254\n",
      "x3           529.9252    243.543      2.176      0.030      50.650    1009.200\n",
      "x4           326.7419    248.223      1.316      0.189    -161.743     815.227\n",
      "x5           181.5677   1485.137      0.122      0.903   -2741.078    3104.213\n",
      "x6          -511.8037   1187.478     -0.431      0.667   -2848.677    1825.070\n",
      "x7           -78.8246    776.199     -0.102      0.919   -1606.330    1448.681\n",
      "x8           465.0394    589.797      0.788      0.431    -695.641    1625.719\n",
      "x9           340.0635    601.944      0.565      0.573    -844.521    1524.648\n",
      "x10          -20.6244    232.680     -0.089      0.929    -478.522     437.273\n",
      "==============================================================================\n",
      "Omnibus:                        5.785   Durbin-Watson:                   0.208\n",
      "Prob(Omnibus):                  0.055   Jarque-Bera (JB):                3.806\n",
      "Skew:                           0.097   Prob(JB):                        0.149\n",
      "Kurtosis:                       2.492   Cond. No.                         22.1\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model = OLS(Y_train, X_train)  # 만들때 dataset을 미리 넣어줘야한다.\n",
    "result = model.fit()\n",
    "print(result.summary())  # summary값 불러낼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn과 마찬가지로 predict라는 함수를 이용하여 예측을 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  79.35604986   90.20826117    8.09194496  -36.97148582   40.24065968\n",
      "   88.24090122  -42.21828014   26.93912291   -3.99031491   79.26578643\n",
      "    8.2648895    28.48101225  -46.80830476  -66.51983831   88.4234783\n",
      "  -45.93179422  -10.8218498   -68.13614387  -55.33360783   47.461923\n",
      "   38.16214497   -4.5447892     6.56759019   -9.10295676   58.2610926\n",
      "    2.44262802  -22.35918837  -74.64330428   30.18044001   10.748149\n",
      "   24.66705442  -64.19173096  -10.9361286    -8.20704161  -23.74519905\n",
      "   28.69400992    1.50861315   46.43380411  -34.79575511   38.32607847\n",
      "  -72.34149797   11.16568701  -22.7465025     9.7993116    34.16128536\n",
      "  -78.18008196  -10.48608231  -16.6095517   -31.83365014   62.23435859\n",
      "    4.93659208  -65.05210695    1.37184048    1.70874549   70.35080937\n",
      "   43.81915436   34.92214274  -31.87574756  -31.74464622   10.93511267\n",
      "   47.87088619    9.0239927     0.59877324  -45.74400118   94.6854663\n",
      "   -7.20058459  -79.07213661   73.78038015   68.60076022  -88.73578827\n",
      "  -71.87549218  -25.36093416  -44.83850007  -15.26730723  -16.2479792\n",
      "   50.09895398  -55.94612877   44.62869315   62.54302854   27.75235629\n",
      "   -8.88028452   55.47367057  -80.74248702   46.81380337  -66.94577287\n",
      "  -68.37900508   -5.49905377   49.89159367  -21.86680658  -12.72993503\n",
      "  -53.61499906  -23.51338426  -59.9059962   -10.54899284  -26.81793916\n",
      "  -49.3573559    82.79223444   56.75191182  -24.89594367    0.1588696\n",
      "   33.72171333  -37.03547454   77.67186109  -74.36158673   65.67226753\n",
      "  -35.85773468   66.85070689  117.06324578  -37.38898189  -36.58097882\n",
      "   32.27233503  -43.78171002   46.41042447  -44.83724316  -47.99016597\n",
      "   49.20657232   80.95721025  -51.10201985  132.44363029  -33.26166038\n",
      "  -29.18903229  -44.32110009  -66.87065004   75.9592981   -51.28596016\n",
      "  -25.29532132   55.21707192   18.64295283   29.46981755   12.62524624\n",
      "   44.0392782   -41.28672788   15.66646905]\n"
     ]
    }
   ],
   "source": [
    "pred = result.predict(X_test)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VIF 구하기(feat. statsmodels 패키지)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIF를 구하기 위해서는 scikit-learn에서는 계산할 수 있는 모듈을 제공하고 있지 않다. 그러므로 다른 모듈을 사용하거나, 직접 계산하는 수 밖에 없다. 다행히, statsmodels 패키지에서 variance_inflation_factor로 제공하고있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "variance_inflation_factor함수는 첫번째 input으로 데이터셋 전체를 받고, 두번째 input으로 vif를 계산할 특정 변수의 index를 입력받는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif['VIF Factor'] = [variance_inflation_factor(X_train, i) for i in range(X_train.shape[1])]  # vif구하는 코드. x_train의 컬럼이 들어가서.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VIF Factor\n",
      "0    1.258764\n",
      "1    1.249004\n",
      "2    1.573517\n",
      "3    1.591749\n",
      "4   56.286046\n",
      "5   36.309338\n",
      "6   15.924893\n",
      "7    9.460528\n",
      "8    9.930956\n",
      "9    1.603518\n"
     ]
    }
   ],
   "source": [
    "print(vif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
